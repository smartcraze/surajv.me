---
title: "AskSuraj – Portfolio RAG Assistant"
description: "A Retrieval-Augmented Generation assistant that answers questions about my portfolio, projects, and experience using semantic search and LLMs."
date: "2025-06-26"
tags: ["fastapi", "langchain", "rag", "ai", "openai", "portfolio"]
video: "https://www.tella.tv/video/cmbz7dul8000b0bji1p1e08a6/embed?b=0&title=0&a=0&loop=0&t=0&muted=0&wt=0"
github: "https://github.com/smartcraze/SurajGPT"
live: "https://ragv2.surajv.me"
---

## AskSuraj – Portfolio RAG Assistant

**Project Overview:**  
AskSuraj is a **Retrieval-Augmented Generation (RAG) assistant** that answers questions about my portfolio, projects, and professional experience. It combines semantic search with a language model to deliver accurate, context-aware responses.  
This project highlights skills in **AI integration, NLP, and full-stack development**, providing a smart interface for recruiters, collaborators, and portfolio viewers.

---

## Key Features

| Feature                        | Description |
|--------------------------------|------------|
| Semantic Search                | Vector-based search over portfolio documents for relevant results |
| LLM-Powered Q&A                | Generates natural language answers using a language model |
| Multi-Document Support         | Handles resume, project write-ups, blogs, and other portfolio content |
| Backend API                    | Built with FastAPI for robust API serving |
| Easy Deployment                | Runs locally or can be hosted for live interaction |

---

## Technologies Used

| Layer       | Tech Stack / Tools                   |
|------------|-------------------------------------|
| Backend     | FastAPI                             |
| RAG Pipeline| LangChain + LangServe                |
| Vector Index| FAISS / Chroma                       |
| AI Model    | OpenAI embeddings / Local LLMs       |
| Frontend    | Simple web interface / API endpoints |

---

## How It Works

```plaintext
User Question → Semantic Search → Retrieve Relevant Docs → LLM Generates Answer → Response to User
